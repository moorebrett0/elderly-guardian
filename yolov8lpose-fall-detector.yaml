axelera-model-format: 1.0.0

name: yolov8lpose-coco

description: yolov8l pose estimation ultralytics v8.1.0, 640x640 (COCO), native PyTorch
  model
# converted from https://github.com/ultralytics/ultralytics

pipeline:
  - yolov8lpose-coco:
      input:
        type: image
      preprocess:
        - letterbox:
            width: 640
            height: 640
            scaleup: True
        - torch-totensor:
      postprocess:
        - decodeyolopose:
            max_nms_boxes: 30000
            conf_threshold: 0.25
            nms_iou_threshold: 0.45
            nms_top_k: 300
            eval:
              conf_threshold: 0.30
              nms_iou_threshold: 0.65
            box_format: xywh
            normalized_coord: False

models:
  yolov8lpose-coco:
    class: AxUltralyticsYOLO
    class_path: $AXELERA_FRAMEWORK/ax_models/yolo/ax_ultralytics.py
    weight_path: weights/yolov8l-pose.pt
    weight_url: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l-pose.pt
    weight_md5: e441163d8d6f430f2fddf8fa82025e64
    task_category: KeypointDetection
    input_tensor_layout: NCHW
    input_tensor_shape: [1, 3, 640, 640]
    input_color_format: RGB
    num_classes: 1
    dataset: CocoDataset-keypoint-COCO2017
    extra_kwargs:
      m2:
        mvm_limitation: 57

datasets: # Python dataloader
  CocoDataset-keypoint-COCO2017:
    class: KptDataAdapter
    class_path: $AXELERA_FRAMEWORK/ax_datasets/objdataadapter.py
    data_dir_name: coco
    label_type: COCO2017
    # TODO: study which representative images are the best
    repr_imgs_dir_path: $AXELERA_FRAMEWORK/data/coco2017_400_b680128
    repr_imgs_url: https://media.axelera.ai/artifacts/data/coco/coco2017_repr400.zip
    repr_imgs_md5: b680128512392586e3c86b670886d9fa
    # without val, will use the default coco2017 val set
    # val_data: dir with yolo label txt files or annotations/person_keypoints_val2017.json
    # if using COCO json format, please specify cal_img_dir / val_img_dir
    # val_img_dir_name: images/val2017

model-env:
  dependencies:
    - ultralytics

operators:
  decodeyolopose:
    class: DecodeYoloPose
    class_path: $AXELERA_FRAMEWORK/ax_models/decoders/yolopose.py
